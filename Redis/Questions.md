## Q:redis 和 memcached 有啥区别？

- 数据结构：redis 相比 memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。
- 原生集群：在 redis3.x 版本中，便能支持 cluster 模式，而 memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。

## Q:Redis性能为什么这么高？

- 纯**内存**操作。
- 高效的数据结构，比如：哈希表、跳表、压缩表。
- **单线程（网络IO和数据读写）**反而避免了多线程上下文切换的开销，避免了锁竞争而导致的性能损耗。
- 核心是基于**非阻塞的IO多路复用**。

### IO多路复用是什么？

I/O多路复用是一个同步IO模型，实现一个线程可以监控多个文件句柄。一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；没有文件句柄就绪时会阻塞应用程序，交出cpu。多路是指网络连接，复用指的是同一个线程。

与传统的 多线程/多进程 模型比，I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源。

#### Select

> 缺点：两次拷贝，两次遍历，1024个文件描述符限制。

- 将已连接的socket都放入一个**文件描述符集合**。
- 然后调用select函数将文件描述符集合**拷贝**到内核里，内核去检查是否有网络事件产生。
- 检查的方式是遍历文件描述符集合，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合**拷贝**回用户态里。
- 然后用户态还需要再通过**遍历**的方法找到可读或可写的 Socket，然后再对其处理。

#### Poll

- 以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。
- 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发时）

#### Epoll

> 解决了两个问题：文件描述符在用户态和内核态之间的大量拷贝、增大了处理文件描述符的能力。

- epoll是通过epoll_create和epoll_ctl和epoll_wait三个系统调用完成的。
- 每当接入一个文件描述符，通过ctl添加到内核维护的红黑树中，增删查的时间复杂度是O(logn)。
- 通过事件驱动机制，内核里**维护了一个链表来记录就绪事件**，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中。
- 当用户调用wait时，获取链表中准备好数据的fd，应用程序去处理。



## Q:Redis为什么要用单线程？

- Redis是基于内存的操作，读取数据很快，不需要在某个线程读取数据时，切换到另一个线程来执行来提高CPU利用率，所以**CPU不会成为瓶颈**所在，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。
- Redis处理网络请求是单线程模型，并通过IO多路复用来提高并发。但在其他模块，比如持久化、异步删除、集群数据同步是由其他的线程执行的。
- 在Redis6.0中采用多个IO线程来处理网络请求，对于读写命令，Redis依然使用单线程来处理。



## Q:Redis的基本数据类型及底层实现方式？

> [Redis五种数据结构的底层实现原理](https://app.yinxiang.com/shard/s43/nl/13675070/f1e81d8b-bb99-4249-9340-d719e5251ba4)

![](./static/WX20210521-145830@2x.png)

### 1、String(字符串)

> 一般用于复杂的计数功能的缓存：商品销量，购买保险数量等。

**底层实现方式:动态字符串sds或者long**

String的内部存储结构一般是sds（Simple Dynamic String，可以动态扩展内存），但是如果一个String类型的value的值是数字，那么Redis内部会把它转成long类型(32或者64)来存储，从而减少内存的使用。

### 2、List(链表)

> 项目中认证的用户列表、粉丝列表

**底层实现方式：双向链表(quicklist) **

### 3、Hash(哈希表)

> 适合用于存储对象，因为一个对象的各个属性，正好对应一个hash结构的各个field。比如用户对象包含昵称，加入时间，头像

**底层实现方式：压缩链表(zaplist)或者字典(dict)**

当满足以下两个条件的时候使用压缩链表，其他情况使用字典。

- 元素数量小于等于512；
- 所有value长度少于64字节。

（注意：这两个数值是通过`hash-max-ziplist-entries`和`hash-max-ziplist-value`选项进行）

### 4、Set(集合)

> set是一个存放不重复值的无序集合，可以做全局去重的功能。基于set可以实现交集、并集、差集的操作，计算共同喜好，全部的喜好，自己独有的喜好等功能。

**底层实现方式：整数集合(intset)或者字典(dict) **

当满足以下两个条件的时候使用整数集合，其他情况使用字典。

- 元素数量小于等于128；
- 所有value长度少于64字节。

### 5、Sorted Set(有序集合)

> 排行榜

**底层实现方式：ziplist(压缩链表)和skiplist(跳表)**

当`sorted set`满足以下两个条件的时候，使用ziplist，不满足这两个条件则使用skiplist。

- 元素数量少于128个。
- 所有member的长度少于64字节。

（注意：这两个数值是通过`redis.conf`的`zset-max-ziplist-entries`和`zset-max-ziplit-value`选项进行）



## Q:为什么有序集合需要同时使用跳跃表和字典来实现？

skiplist编码的有序集合对象使用zset结构作为底层实现，一个zset结构同时包含一个字典和一个跳跃表

```cpp
typedef struct zset{
     //跳跃表
     zskiplist *zsl;
     //字典
     dict *dice;
} zset;
```

字典的键保存元素的值，字典的值则保存元素的分值；跳跃表节点的 object 属性保存元素的成员，跳跃表节点的 score 属性保存元素的分值。

这两种数据结构会**通过指针来共享相同元素的成员和分值**，所以不会产生重复成员和分值，造成内存的浪费。



- 字典，虽然能以 O(1) 的时间复杂度查找成员的分值，但是因为字典是以无序的方式来保存集合元素，所以**每次进行范围操作的时候都要进行排序**；
- 跳跃表来实现，虽然能执行范围操作，**但是查找操作有 O(1)的复杂度变为了O(logN)**。

#### Reference

[有序集合的底层数据结构](https://app.yinxiang.com/shard/s43/nl/13675070/896c9608-224a-4c97-8527-77c0652aae05)



## Q:底层数据结构-dict（字典）

> 冲突解决方法：拉链法
>
> 扩容：增量扩容、rehash分散在各个增删改查中。

 dict 也是一个基于哈希表的算法。和传统的哈希算法类似，它采用哈希函数从 key 计算得到在哈希表中的位置，采用 **拉链法** 解决冲突，并在装载因子（load factor）超过预定值时自动扩展内存，引发重哈希（rehashing）。

Redis 的 dict 实现最显著的一个特点，就在于它的重哈希。它采用了一种称为 **增量式重哈希（incremental rehashing）** 的方法，在需要扩展内存时避免一次性对所有 key 进行重哈希，而是将重哈希操作分散到对于 dict 的各个增删改查的操作中去。这种方法能做到每次只对一小部分 key 进行重哈希，而每次重哈希之间不影响 dict 的操作。

dict之所以这样设计，是为了避免重哈希期间单个请求的响应时间剧烈增加，这与前面提到的“快速响应时间”的设计原则是相符的。

为了实现增量式重哈希（incremental rehashing），dict的数据结构里包含两个哈希表。在重哈希期间，数据从第一个哈希表向第二个哈希表迁移。



## Q:底层数据结构-sds(动态字符串)

```c
/*  
 * 保存字符串对象的结构  
 */  
struct sdshdr {  
    int len;  // buf 中已占用空间的长度  
    int free;  // buf 中剩余可用空间的长度
    char buf[];  // 数据空间  
};
```

SDS 相比C 字符串的优势：

- **获取字符串长度的复杂度为 O(1) **。SDS保存了字符串的长度，而C字符串不保存长度，需要遍历整个数组（找到’\0’为止）才能取到字符串长度。
- **防止缓冲区溢出**。修改SDS时，检查给定SDS空间是否足够，如果不够会先拓展SDS 的空间，防止缓冲区溢出。C字符串不会检查字符串空间是否足够，调用一些函数时很容易造成缓冲区溢出（比如strcat字符串连接函数）。
- **减少修改字符串时带来的内存重分配次数**。空间预分配，惰性空间释放。
  - 惰性空间释放用于优化SDS的字符串缩短操作：当SDS的API需要缩短SDS保存的字符串时，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录起来，并等待将来使用。



## Q:底层数据结构-ziplist

`ziplist`是一个经过特殊编码的双向链表，它的设计目标是为了提高存储效率。ziplist可以用于存储字符串或整数，其中整数是按真正的二进制表示进行编码的，而不是编码成字符串序列。它能以O(1)的时间复杂度在表的两端提供`push`和`pop`操作。

实际上，ziplist充分体现了Redis对于存储效率的追求。一个普通的双向链表，链表中每一项都占用独立的一块内存，各项之间用地址指针（或引用）连接起来。这种方式会带来大量的内存碎片，而且地址指针也会占用额外的内存。而ziplist却是将表中每一项存放在前后连续的地址空间内，一个ziplist整体占用一大块内存。它是一个表（list），但其实不是一个链表（linked list）。

另外，ziplist 为了在细节上节省内存，对于值的存储采用了 **变长编码方式**，大概意思是说，对于大的整数，就多用一些字节来存储，而对于小的整数，就少用一些字节来存储。ziplist 的底层结构如下所示：

#### 当ziplist变得很大的时候，它有如下几个缺点：

- 每次插入或修改引发的 realloc 操作会有更大的概率造成内存拷贝，从而降低性能。
- 一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。
- 当 ziplist 数据项过多的时候，在它上面查找指定的数据项就会性能变得很低，因为 ziplist 上的查找需要进行遍历。

## Q:底层数据结构-skiplist

- 一般查找问题的解法分为两大类：平衡树、哈希表。
- skiplist是在有序链表基础上的多层链表。
- 节点插入时会随机出链表的层数，计算过程：
  - 首先，每个节点肯定都有第1层指针（每个节点都在第1层链表里）。
  - 如果一个节点有第i层(i>=1)指针（即节点已经在第1层到第i层链表中），那么它有第(i+1)层指针的概率为p( p = 1/4 )。
  - 节点最大的层数不允许超过一个最大值，记为MaxLevel( MaxLevel = 32 )。



## Q:底层数据结构-intset

intset是一个由整数组成的有序集合，从而便于在上面进行二分查找，用于快速地判断一个元素是否属于这个集合。它在内存分配上与ziplist有些类似，是连续的一整块内存空间，而且对于大整数和小整数（按绝对值）采取了不同的编码，尽量对内存的使用进行了优化。

#### intset与ziplist对比：

- ziplist可以存储任意二进制串，而intset只能存储整数。
- ziplist是无序的，而intset是从小到大有序的。因此，在ziplist上查找只能遍历，而在intset上可以进行二分查找，性能更高。
- ziplist可以对每个数据项进行不同的变长编码（每个数据项前面都有数据长度字段len），而intset只能整体使用一个统一的编码（encoding）。

默认每个quicklist节点上的ziplist大小不能超过8 Kb。

## Q:skiplist与平衡树、哈希表的比较，或者说Redis为甚用跳表而不用平衡树？

> 从使用场景、数据结构、内存占用、实现难度描述

[Redis为什么用跳表而不用平衡树？](https://app.yinxiang.com/shard/s43/nl/13675070/fad53dc3-be67-4914-a2df-7e2e1b3f8f6d)

- **skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的**。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。
- **查找单个key**，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。
- **在做范围查找的时候，平衡树比skiplist操作要复杂**。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。
- 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。
- 从**内存占用**上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小(skiplist的层数是随机出来的)。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。
- 从算法实现难度上来比较，skiplist比平衡树要简单得多。



## Q: rehash

- redis的哈希表使用**拉链法**解决键冲突。使用**MurmurHash2算法**。

#### 扩容条件：

> 也可以说：负载因子超过预定值时自动扩容。

- 服务器目前没有在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子大于等于1。
- 服务器目前正在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子大于等于5。

#### 扩容后的大小：

- 扩展后ht[1]的大小为第一个大于或者等于`ht[0].used*2`的2的n次方幂(收缩操作的大小也是这样)。比如：ht[0].used当前的值为4，4*2=8，而8（2 3）恰好是第一个大于等于4的2的n次方，所以程序会将ht[1]哈希表的大小设置为8。

#### 缩容条件：

- 当哈希表的负载因子小于0.1时，程序自动开始对哈希表执行收缩操作。

#### 渐进式rehash

> ht[0]:旧空间。
>
> ht[1]:新空间。

- 为了避免rehash对服务器性能造成影响，服务器不是一次性将ht[0]里面的所有键值对全部rehash到ht[1]，而是分多次、渐进式地将ht[0]里面的键值对慢慢地rehash到ht[1]。

#### 渐进式rehash期间的哈希表操作

- 因为在进行渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除（delete）、查找（find）、更新（update）等操作**会在两个哈希表上进行**。
- 在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作，这一措施保证了ht[0]包含的键值对数量会只减不增，并随着rehash操作的执行而最终变成空表。  



## Q:持久化

### RDB

- 进程中的数据生成快照保存到硬盘
- 启动时可以读取快照文件恢复数据
- 一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis 进程宕机，那么会丢失最近 5 分钟的数据。
- RDB 每次在 `fork` 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。

### AOF
- AOF是将Redis执行的命令记录到日志文件中
- 实时性更好，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 `fsync` 操作，最多丢失 1 秒钟的数据。
- 文件过大的时候会触发AOF的重写，通过对过期数据、无效命令、命令合并的方式压缩文件。
- AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低

###  RDB 和 AOF 到底该如何选择

- 不要仅仅使用 RDB，因为那样会导致你丢失很多数据；
- 也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；
- Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。

### Reference

[Reids持久化](https://www.cnblogs.com/kismetv/p/9137897.html)



## Q:Redis数据淘汰机制

### 对象过期策略

Redis回收过期对象的策略：定期删除+惰性删除

- **惰性删除**：在访问key时，如果发现key已经过期，那么会将key删除。
- **定期删除**：Redis会定期随机抽取设置过期时间的key，主动淘汰一批已过期的key。

### 内存不够时清理

- 第一类 不处理，等报错(默认的配置)

  - noeviction，发现内存不够时，不删除key，执行写入命令时发现内存不够直接返回错误信息。（Redis默认的配置就是noeviction）

- 第二类 从所有结果集中的key中挑选，进行淘汰(随机，lru，lfu三种)

  - allkeys-random 就是从所有的key中**随机**挑选key，进行淘汰
  - allkeys-lru 就是从所有的key中挑选**最近使用时间距离现在最远**的key，进行淘汰
  - allkeys-lfu 就是从所有的key中挑选**使用频率最低**的key，进行淘汰。（这是Redis 4.0版本后新增的策略）

- 第三类 从设置了过期时间的key中挑选，进行淘汰(随机，lru，ttl，lfu)

  这种就是从设置了expires过期时间的结果集中选出一部分key淘汰，挑选的算法有：

  - volatile-random 从设置了过期时间的结果集中**随机**挑选key删除。
  - volatile-lru 从设置了过期时间的结果集中挑选**上次使用时间距离现在最久**的key开始删除
  - volatile-ttl 从设置了过期时间的结果集中挑选可存活时间最短的key开始删除(也就是从哪些**快要过期**的key中先删除)
  - volatile-lfu 从过期时间的结果集中选择使用**频率最低**的key开始删除（这是Redis 4.0版本后新增的策略）
  




## Q:Redis主从架构

单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑**读高并发**的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的**读请求全部走从节点**。这样也可以很轻松实现水平扩容，**支撑读高并发**。

### 主从复制原理：

- `slave node`初次连接到`master node`会触发全量复制（无法进行部分复制也会使用全量复制）。

- 主节点开启后台线程，生成RDB快照，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。

  RDB` 文件生成完毕后， master 会将这个 `RDB` 发送给 slave，slave 会先**写入本地磁盘，然后再从本地磁盘加载到内存**中。

-  master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。

- slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。

### 心跳检测

主从节点互相都会发送 heartbeat 信息。

master 默认每隔 10秒 发送一次 heartbeat，slave node 每隔 1秒 发送一个 heartbeat。

###  过期key处理
- slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。



## Q:哨兵

### 主要功能

- **集群监控**：负责监控 redis master 和 slave 进程是否正常工作。
- **故障转移**：如果 master node 挂掉了，会自动转移到 slave node 上。
- 消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
- 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。

### 哨兵核心知识

- 哨兵至少需要 3 个实例，来保证自己的健壮性。
- 哨兵 + redis 主从的部署架构，是**不保证数据零丢失**的，只能保证 redis 集群的**高可用**性。
- 对于哨兵 + redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。

### 脑裂问题

- **原因**：脑裂，也就是说，某个 master 所在机器突然**脱离了正常的网络**，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会**认为** master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的**脑裂**。

- **影响：**虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。
- **解决方案：**要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。

### 宕机的监控

- sdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机。
- odown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机。

### slave->master的选举算法

如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作。

如果一个 slave 跟 master 断开连接的时间已经超过了 `down-after-milliseconds` 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。

接下来会对 slave 进行排序：

- 按照 slave 优先级进行排序，slave priority（配置文件中设置） 越低，优先级就越高。
- 如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。
- 如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。

### 领导者哨兵的选举

- Raft算法：监视主节点的所有哨兵都有可能被选为领导者，选举使用的算法是Raft算法；Raft算法的基本思路是先到先得：即在一轮选举中，哨兵A向B发送成为领导者的申请，如果B没有同意过其他哨兵，则会同意A成为领导者。选举的具体过程这里不做详细描述，一般来说，哨兵选择的过程很快，谁先完成客观下线，一般就能成为领导者。

### Reference

[Redis 哨兵集群实现的高可用](https://app.yinxiang.com/shard/s43/nl/13675070/c66ba4de-37fe-4193-a398-df1e6079c280)



## Q:数据分区算法

> 算法主要解决的是数据分区问题

### 哈希取余

- 计算key的hash值，然后对节点数量进行取余，从而决定数据映射到哪个节点上。
- **缺点：**当新增或删减节点时，节点数量发生变化，系统中所有的数据都需要重新计算映射关系，引发大规模数据迁移。

### 一致性哈希

- 将整个哈希值空间组织成一个虚拟的圆环，如下图所示，范围为0-2^32-1；对于每个数据，根据key计算hash值，确定数据在环上的位置，然后从此位置沿环顺时针行走，找到的第一台服务器就是其应该映射到的服务器。
- **缺点：**当节点数量较少时，增加或删减节点，对单个节点的影响可能很大，造成数据的严重不平衡。

### 带虚拟节点的一致性哈希分区

- 在一致性哈希分区的基础上，引入了虚拟节点的概念。**Redis集群中的虚拟节点称为槽**。引入槽以后，数据的映射关系由数据hash->实际节点，变成了数据**hash->槽->实际节点**。
- 在使用了槽的一致性哈希分区中，槽是数据管理和迁移的基本单位。槽解耦了数据和实际节点之间的关系，增加或删除节点对系统的影响很小。
- 槽的数量一般远小于2^32，远大于实际节点的数量；在Redis集群中，槽的数量为16384，使用的算法是CRC16。

### 节点间通信机制

- 两个端口

  - 普通端口：为客户端提供服务（与单机节点类似）；但在节点间数据迁移时也会使用。
  - 集群端口：端口号是普通端口+10000（10000是固定值，无法改变），集群端口只用于节点之间的通信，如搭建集群、增减节点、故障转移等操作时节点间的通信。
- Gossip协议
  - 在节点数量有限的网络中，每个节点都“随机”的与部分节点通信（并不是真正的随机，而是根据特定的规则选择通信的节点），经过一番杂乱无章的通信，每个节点的状态很快会达到一致。
  - 优点：有负载(比广播)低、去中心化、容错性高(因为通信有冗余)等。
  - 缺点：主要是集群的收敛速度慢。

- Gossip协议类型

  > 集群中的节点采用固定频率（每秒10次）的定时任务进行通信相关的工作

  - meet：某个节点收到客户端的CLUSTER MEET命令时，发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。
  - ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。
  - pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。
  - fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机了。

### 高可用与主备切换

#### 集群伸缩

- Redis集群可以在不影响对外服务的情况下实现伸缩；**伸缩的核心是槽迁移：修改槽与节点的对应关系，实现槽(即数据)在节点之间的移动**
- 在迁移过程中，如果客户端向正在迁移的源节点发送命令，会收到ASK错误。

#### 判断节点宕机

- 如果一个节点认为另外一个节点宕机，那么就是 `pfail`，**主观宕机**。如果多个节点都认为另外一个节点宕机了，那么就是 `fail`，**客观宕机**。
- 在 `cluster-node-timeout` 内，某个节点一直没有返回 `pong`，那么就被认为 `pfail`。
- 如果一个节点认为某个节点 `pfail` 了，那么会在 `gossip ping` 消息中，`ping` 给其他节点，如果**超过半数**的节点都认为 `pfail` 了，那么就会变成 `fail`。

- FAIL 状态是单向的，只能从 PFAIL 升级为 FAIL ，当节点重新可达时，可清除 FAIL 标记。

#### 从节点选举

每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。

所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node`（N/2 + 1）`都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。

从节点执行主备切换，从节点切换为主节点。




## Q:缓存雪崩如何解决

**缓存雪崩**是指短时间内大量key失效，导致所有请求全部转向数据库，导致数据库压力过大。

**解决方案**

- 在给缓存设置失效时间时加一个随机值，避免集体失效。
- 双缓存，本地缓存 + redis缓存。

##### 缓存雪崩的事前事中事后的解决方案如下。

- 事前：redis 高可用，主从+哨兵，redis cluster，缓存设置随机过期时间避免全盘崩溃。
- 事中：本地内存缓存(Java有ehcache缓存) + 限流&降级，避免 MySQL 被打死。
- 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。



## Q:缓存穿透如何解决

Redis 缓存穿透指的是攻击者故意大量请求一些Redis缓存中不存在key的数据，导致请 求打到数据库上，导致数据库压力过大。

**解决方案**

1. 做好参数校验，无效的请求直接返回，只能避免一部分情况，攻击者总是可以找到一些没有覆盖的情况。
2. 对缓存中找不到的key，需要去数据库查找的key，缓存到Redis中，但是可能会导致Redis中缓存大量无效的key，可以设置一个很短的过期时间，例如1分钟。
3. 也可以使用布隆过滤器，将所有可能的存在的数据通过去hash值的方式存入到一个足够大的bitmap中去，处理请求时，通过在bitmap中查找，可以将不存在的数据拦截掉。



## Q:缓存击穿如何解决

缓存击穿主要指的是某个热点key失效，导致大量请求全部转向数据库，导致数据库压力过大。

**解决方案**

1. 对热点key设置永不过期。
2. 加互斥锁，缓存中没有热点key对应的数据时，等待100ms，由获得锁的线程去读取数据库然后设置缓存。



## Q:解决缓存与数据库一致性问题？

> 分析缓存与数据库一致性问题需要考虑业务中具体的 读写 规模。

严格`数据库+缓存`一致性方案：

- 读写分离：读请求只访问缓存，写请求修改数据库和缓存
- **读请求和写请求串行化**，串行到一个**内存队列**中去。



### 常用的缓存更新策略

#### Cache Aside Pattern

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，**先更新数据库，然后再删除缓存**。

缺点：在更新数据库成功，删除缓存失败的情况下，数据会造成不一致。



### Reference

[如何保证数据库与缓存一致性](https://app.yinxiang.com/shard/s43/nl/13675070/f4ee0e90-4458-4a79-8c88-137c740c799b)

[石彬 双写一致方案](https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/high-concurrency/redis-consistence.md)



## Q:Redis事务

> redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。

#### Redis事务的三个阶段

1. 事务开始 MULTI
2. 命令入队
3. 事务执行 EXEC

事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入队列中排队

#### Redis事务相关命令

Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的

Redis会将一个事务中的所有命令序列化，然后按顺序执行。

1. **redis 不支持回滚**，“Redis 在事务失败时不进行回滚，而是继续执行余下的命令”， 所以 Redis 的内部可以保持简单且快速。
2. **如果在一个事务中的命令出现错误，那么所有的命令都不会执行**；
3. **如果在一个事务中出现运行错误，那么正确的命令会被执行**。

- WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。
- MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。
- EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。 当操作被打断时，返回空值 nil 。
- 通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。
- UNWATCH命令可以取消watch对所有key的监控。

#### Redis事务保证原子性吗，支持回滚吗

Redis中，单条命令是原子性执行的，但**事务不保证原子性，且没有回滚**。事务中任意命令执行失败，其余的命令仍会被执行。

### reference

[Redis 事务及乐观锁](https://app.yinxiang.com/shard/s43/nl/13675070/522edfee-9b93-4141-abe1-4583f25c4da6)



### 集群方案

#### Redis哈希槽概念

Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。

在redis节点发送心跳包时需要把所有的槽放到这个心跳包里，以便让节点知道当前集群信息，16384=16k，在发送心跳包时使用char进行bitmap压缩后是2k（2 * 8 (8 bit) * 1024(1k) = 16K），也就是说使用2k的空间创建了16k的槽数。

详解：[为什么Redis集群有16384个槽](https://www.cnblogs.com/rjzheng/p/11430592.html)

#### Redis集群最大节点个数是多少

16384



### 其他问题

[Redis面试题](https://cloud.tencent.com/developer/article/1612347)

#### Redis与Memcached的区别

[redis和memcached的区别](https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/high-concurrency/redis-single-thread-model.md)

#### 如何保证缓存与数据库双写时的数据一致性？

[如何保证数据库与缓存的双写一致](https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/high-concurrency/redis-consistence.md)

#### 布隆过滤器

##### 简介

布隆过滤器（Bloom Filter）是一个基于hash的概率性的数据结构，它实际上是一个很长的二进制向量，可以检查一个元素可能存在集合中，和一定不存在集合中。它的优点是空间效率高，但是有一定false positive(元素不在集合中，但是布隆过滤器显示在集合中)。

##### 原理

布隆过滤器就是一个长度为`m`个bit的bit数组，初始的时候每个bit都是0，另外还有`k`个hash函数。

当加入一个元素时，先用`k`个hash函数得到`k`个hash值，将`k`个hash值与bit数组长度取模得到个`k`个位置，将这`k`个位置对应的bit置位1。

参数设置参考

[白话布隆过滤器](https://blog.huoding.com/2020/06/22/825)

##### 实现

hash函数的选择，murmur3、FNV

[Redis实现布隆过滤器](https://learnku.com/articles/46442)

