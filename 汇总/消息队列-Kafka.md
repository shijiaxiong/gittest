## Q:Kafka版本号

- 0.7版本：只提供了最基础的消息队列功能。
- 0.8版本：引入了副本机制，至此Kafka成为了一个真正意义上完备的分布式高可靠消息队列解决方案。
- 0.9版本：增加了基础的安全认证/权限功能；使用java重写了新版本消费者API；引入Kafka Connect组件。
- 0.10版本：引入Kafka Streams，正式升级成分布式流处理平台。
- 0.11版本(当前使用版本)：提供了幂等性ProducerApi 以及事务API；对Kafka消息格式做了重构。
- 1.0和2.0版本：主要还是Kafka Streams的各种改进。



## Q:为什么使用消息队列，不同消息队列的对比。

### 1、消息队列的作用：解耦、异步、削峰

- 解耦：将生产者和消费者解耦，消费者新增或者减少并不影响生产者的工作。如：支付服务完成后，通过消息通知其他服务。

- 异步：某一项操作完成之后生成消息立即返回。如下单完成之后，依赖订单的发货等其他服务可以异步执行。
- 削峰：上下游服务的处理能力差距比较大，通过消息队列可以缓解下游服务的压力。

### 2、带来的缺点

- 系统的可用性降低：外部依赖越多，系统的可用性就会越低。需要保证消息队列的高可用。
- 系统复杂度提高：加入消息队列，需要考虑消息的重复消费、消息丢失、消息传递的顺序性等问题。
- 一致性问题：解耦或者异步之后要保证数据的最终一致性。

### 3、不同消息的对比

| 特性                     | ActiveMQ                              | RabbitMQ                                           | RocketMQ                                                     | Kafka                                                        |
| ------------------------ | ------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量               | 万级，比 RocketMQ、Kafka 低一个数量级 | 同 ActiveMQ                                        | 10 万级，支撑高吞吐                                          | 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic 数量对吞吐量的影响 |                                       |                                                    | topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 |
| 时效性                   | ms 级                                 | 微秒级，这是 RabbitMQ 的一大特点，延迟最低         | ms 级                                                        | 延迟在 ms 级以内                                             |
| 可用性                   | 高，基于主从架构实现高可用            | 同 ActiveMQ                                        | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性               | 有较低的概率丢失数据                  | 基本不丢                                           | 经过参数优化配置，可以做到 0 丢失                            | 同 RocketMQ                                                  |
| 功能支持                 | MQ 领域的功能极其完备                 | 基于 erlang 开发，并发能力很强，性能极好，延时很低 | MQ 功能较为完善，还是分布式的，扩展性好                      | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 |

- Kafka消息吞吐量大，支持大数据领域的实时计算、日志采集等场景。



## Q:Kafka高可用性如何做的

- **消息分布式：** Kafka集群由多个 broker 组成，每个 broker 是一个节点；对于每一个 topic 可以划分为多个 partition，每个 partition 负责存储一部分数据。
- **多副本机制：** Kafka 0.8之后，引入了多副本机制。包括一个Leader副本和多个Follower副本。所有副本会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他副本就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。
  - 如果某个broker宕机，可以使用其他副本机器。如果这个broker上还有某个partition的leader，则会从 follower 中**重新选举**一个新的 leader 出来。
- leader和follower之间的数据同步通过Ack参数保证。
  - 参数为 0：生产者只管发送，不管是否落盘。如果消息传递过程中，broker宕机，则会造成数据丢失。
  - 参数为1：生产者只管partition leader写成功就返回成功。如果follower还没来得及同步消息，leader就挂掉了，会造成消息丢失。
  - 参数all(应该一个leader和至少一个follower)：在leader接收到消息后，要求 ISR （in-sync replicas 保持同步的副本）列表里的所有follower同步得到消息才能认为消息是成功的。

- leader的选取：
  - 先选举Kafka集群的controller。选举方式是zk的分布式锁，哪个broker能够成功创建/controller这个临时（EPHEMERAL）节点他就可以成为Kafka Controller。
  - 分区leader副本由controller具体操作。选取副本集合中第一个副本为优先副本。



## Q:如何保证消费消费的幂等性? 如何保证消息不被重复消费？

- 需要消费者保证消息的幂等性。



## Q:如何保证可靠性传输？如何解决消息丢失的问题？

### 1、 消费者端丢失数据

- 场景：消费者启用自动提交offset的功能，在还没有处理成功时就异常退出了。
- 解决方案：关闭自动提交offset，处理完成之后再提交。可以采用混合提交方式：对消费者进行异步批次提交并且在关闭时同步提交。

### 2、kafka如何防止弄丢数据

- 每个partition至少两个副本(一个leader,一个follower)。
- 一个 leader 至少感知到有至少一个 follower 还跟自己保持联系。
- asks设置为all,必须写入所有副本才算成功。
- 在 producer 端设置 `retries=MAX` （很大很大很大的一个值，无限次重试的意思）：这个是**要求一旦写入失败，就无限重试**，卡在这里了。

### 3、生产者弄丢数据

- 设置了 `acks=all` ，在 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功
- 失败则重试。



## Q:如何保证消息顺序执行？

- 消息在**生产**的时候，可以指定一个key，kafka会按照key进行哈希，相同key去一个partition。同一个partition中数据是顺序的。



## Q:如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？

### 1、几百万消息积压几小时解决方案：

>  消费者故障造成的消息积压。积压几百上千万条数据。消费者恢复后需要较长时间才能恢复。

- 修复consumer的问题，确保其消费速度，然后将consumer停掉。
- 新建一个topic、partition是原来的10倍。临时建好之前10倍的queue。
- 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，**消费之后不做耗时的处理**，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
- 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
- 等快速消费完积压数据之后，**得恢复原先部署的架构**，**重新**用原先的 consumer 机器来消费消息。



## Q:Kafka和Redis的区别和各自的优缺点？

### 区别

- 存储介质不同：
  - redis数据是存储在内存，虽然有AOF和RDB的持久化方式，但是还是以内存为主。
  - kafka存储在硬盘上。
- 性能不同：redis支持瞬间并发。抢红包场景可以使用。
- 成本不同：硬盘成本低于内存。
- 可靠性：Redis的AOF持久化如果是每秒写盘，会存在消息丢失的情况。
- 部署：redis比较轻量级，kafka需要在部署zk。

### Redis使用场景

- 优点：
  - 部署方便。
  - 5.0版本之后streams数据类型可以创建多个消费者组，消费者组内再挂多个消费者分担读取消息进行消费。
- 缺点：
  - 可能会出现消息丢失。

- 快产快消的场景。生成的消息可以被消费者立即消费掉。
- 允许出现消息丢失。
- 不需要系统保存发送过的消息。
- 处理的数据量不巨大。

### Kafka使用场景

- 消息队列稳定
- 发送过的消息可以保留一段时间。
- 需要处理的数据量巨大。





## Reference

[Kafka分区数和消费者数如何确定](https://app.yinxiang.com/shard/s43/nl/13675070/97a6991a-b13d-4099-810b-d97873b0c149)